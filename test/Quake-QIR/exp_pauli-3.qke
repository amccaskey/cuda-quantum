// ========================================================================== //
// Copyright (c) 2022 - 2024 NVIDIA Corporation & Affiliates.                 //
// All rights reserved.                                                       //
//                                                                            //
// This source code and the accompanying materials are made available under   //
// the terms of the Apache License 2.0 which accompanies this distribution.   //
// ========================================================================== //

// RUN: cudaq-opt --add-dealloc --canonicalize --quake-to-qir %s | FileCheck %s


module attributes {quake.mangled_name_map =
  {__nvqpp__mlirgen__Z4mainE3$_0 = "_ZZ4mainENK3$_0clEd"}} {
  
  func.func @__nvqpp__mlirgen__Z4mainE3$_0(%arg0: f64) attributes {"cudaq-entrypoint", "cudaq-kernel"} {
    %0 = cc.alloca f64
    cc.store %arg0, %0 : !cc.ptr<f64>
    %1 = quake.alloca !quake.veq<4>
    %2 = quake.extract_ref %1[0] : (!quake.veq<4>) -> !quake.ref
    quake.x %2 : (!quake.ref) -> ()
    %3 = quake.extract_ref %1[1] : (!quake.veq<4>) -> !quake.ref
    quake.x %3 : (!quake.ref) -> ()
    %4 = cc.load %0 : !cc.ptr<f64>
    %5 = cc.string_literal "XXXY" : !cc.ptr<!cc.array<i8 x 5>>
    %6 = quake.extract_ref %1[0] : (!quake.veq<4>) -> !quake.ref
    %7 = quake.extract_ref %1[1] : (!quake.veq<4>) -> !quake.ref
    %8 = quake.extract_ref %1[2] : (!quake.veq<4>) -> !quake.ref
    %9 = quake.extract_ref %1[3] : (!quake.veq<4>) -> !quake.ref
    %10 = quake.concat %6, %7, %8, %9 : (!quake.ref, !quake.ref, !quake.ref, !quake.ref) -> !quake.veq<4>
    quake.exp_pauli %4, %10, %5 : (f64, !quake.veq<4>, !cc.ptr<!cc.array<i8 x 5>>) -> ()
    return
  }
}

// CHECK-LABEL:   llvm.func @__nvqpp__mlirgen__Z4mainE3$_0(
// CHECK-SAME:      %[[VAL_0:.*]]: f64)
// CHECK:           %[[VAL_1:.*]] = llvm.mlir.constant(1 : i32) : i32
// CHECK:           %[[VAL_2:.*]] = llvm.alloca %[[VAL_1]] x f64 : (i32) -> !llvm.ptr
// CHECK:           llvm.store %[[VAL_0]], %[[VAL_2]] : f64, !llvm.ptr
// CHECK:           %[[VAL_3:.*]] = llvm.mlir.constant(4 : i64) : i64
// CHECK:           %[[VAL_4:.*]] = llvm.call @__quantum__rt__qubit_allocate_array(%[[VAL_3]]) : (i64) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_5:.*]] = llvm.mlir.constant(0 : i64) : i64
// CHECK:           %[[VAL_6:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_4]], %[[VAL_5]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           llvm.call @__quantum__qis__x(%[[VAL_6]]) : (!llvm.target<"qir#Qubit">) -> ()
// CHECK:           %[[VAL_7:.*]] = llvm.mlir.constant(1 : i64) : i64
// CHECK:           %[[VAL_8:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_4]], %[[VAL_7]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           llvm.call @__quantum__qis__x(%[[VAL_8]]) : (!llvm.target<"qir#Qubit">) -> ()
// CHECK:           %[[VAL_9:.*]] = llvm.load %[[VAL_2]] : !llvm.ptr -> f64
// CHECK:           %[[VAL_10:.*]] = llvm.mlir.addressof @cstr.5858585900 : !llvm.ptr
// CHECK:           %[[VAL_11:.*]] = llvm.mlir.constant(0 : i64) : i64
// CHECK:           %[[VAL_12:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_4]], %[[VAL_11]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           %[[VAL_13:.*]] = llvm.mlir.constant(1 : i64) : i64
// CHECK:           %[[VAL_14:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_4]], %[[VAL_13]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           %[[VAL_15:.*]] = llvm.mlir.constant(2 : i64) : i64
// CHECK:           %[[VAL_16:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_4]], %[[VAL_15]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           %[[VAL_17:.*]] = llvm.mlir.constant(3 : i64) : i64
// CHECK:           %[[VAL_18:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_4]], %[[VAL_17]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           %[[VAL_19:.*]] = llvm.mlir.constant(0 : i64) : i64
// CHECK:           %[[VAL_20:.*]] = llvm.mlir.constant(1 : i64) : i64
// CHECK:           %[[VAL_21:.*]] = llvm.mlir.constant(8 : i32) : i32
// CHECK:           %[[VAL_22:.*]] = llvm.call @__quantum__rt__array_create_1d(%[[VAL_21]], %[[VAL_20]]) : (i32, i64) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_23:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_22]], %[[VAL_19]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           llvm.call @__quantum__rt__array_set_qubit_element(%[[VAL_22]], %[[VAL_19]], %[[VAL_23]]) : (!llvm.target<"qir#Array">, i64, !llvm.target<"qir#Qubit">) -> ()
// CHECK:           %[[VAL_24:.*]] = llvm.call @__quantum__rt__array_create_1d(%[[VAL_21]], %[[VAL_20]]) : (i32, i64) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_25:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_24]], %[[VAL_19]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           llvm.call @__quantum__rt__array_set_qubit_element(%[[VAL_24]], %[[VAL_19]], %[[VAL_25]]) : (!llvm.target<"qir#Array">, i64, !llvm.target<"qir#Qubit">) -> ()
// CHECK:           %[[VAL_26:.*]] = llvm.call @__quantum__rt__array_concatenate(%[[VAL_22]], %[[VAL_24]]) : (!llvm.target<"qir#Array">, !llvm.target<"qir#Array">) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_27:.*]] = llvm.call @__quantum__rt__array_create_1d(%[[VAL_21]], %[[VAL_20]]) : (i32, i64) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_28:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_27]], %[[VAL_19]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           llvm.call @__quantum__rt__array_set_qubit_element(%[[VAL_27]], %[[VAL_19]], %[[VAL_28]]) : (!llvm.target<"qir#Array">, i64, !llvm.target<"qir#Qubit">) -> ()
// CHECK:           %[[VAL_29:.*]] = llvm.call @__quantum__rt__array_concatenate(%[[VAL_26]], %[[VAL_27]]) : (!llvm.target<"qir#Array">, !llvm.target<"qir#Array">) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_30:.*]] = llvm.call @__quantum__rt__array_create_1d(%[[VAL_21]], %[[VAL_20]]) : (i32, i64) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_31:.*]] = llvm.call @__quantum__rt__array_get_qubit_element(%[[VAL_30]], %[[VAL_19]]) : (!llvm.target<"qir#Array">, i64) -> !llvm.target<"qir#Qubit">
// CHECK:           llvm.call @__quantum__rt__array_set_qubit_element(%[[VAL_30]], %[[VAL_19]], %[[VAL_31]]) : (!llvm.target<"qir#Array">, i64, !llvm.target<"qir#Qubit">) -> ()
// CHECK:           %[[VAL_32:.*]] = llvm.call @__quantum__rt__array_concatenate(%[[VAL_29]], %[[VAL_30]]) : (!llvm.target<"qir#Array">, !llvm.target<"qir#Array">) -> !llvm.target<"qir#Array">
// CHECK:           %[[VAL_33:.*]] = llvm.mlir.constant(1 : i32) : i32
// CHECK:           %[[VAL_34:.*]] = llvm.alloca %[[VAL_33]] x !llvm.struct<(ptr, i64)> : (i32) -> !llvm.ptr
// CHECK:           %[[VAL_35:.*]] = llvm.mlir.constant(0 : i64) : i64
// CHECK:           %[[VAL_36:.*]] = llvm.mlir.constant(1 : i64) : i64
// CHECK:           %[[VAL_37:.*]] = llvm.mlir.constant(4 : i64) : i64
// CHECK:           %[[VAL_38:.*]] = llvm.getelementptr %[[VAL_34]]{{\[}}%[[VAL_35]], 0] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.struct<(ptr, i64)>
// CHECK:           llvm.store %[[VAL_10]], %[[VAL_38]] : !llvm.ptr, !llvm.ptr
// CHECK:           %[[VAL_39:.*]] = llvm.getelementptr %[[VAL_34]]{{\[}}%[[VAL_35]], 1] : (!llvm.ptr, i64) -> !llvm.ptr, !llvm.struct<(ptr, i64)>
// CHECK:           llvm.store %[[VAL_37]], %[[VAL_39]] : i64, !llvm.ptr
// CHECK:           llvm.call @__quantum__qis__exp_pauli(%[[VAL_9]], %[[VAL_32]], %[[VAL_34]]) : (f64, !llvm.target<"qir#Array">, !llvm.ptr) -> ()
// CHECK:           llvm.call @__quantum__rt__qubit_release_array(%[[VAL_4]]) : (!llvm.target<"qir#Array">) -> ()
// CHECK:           llvm.return
// CHECK:         }

